{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Destiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando pacotes e baixando banco de dados disponibilizado pela CVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de Manipulação de Dados e Visualização\n",
    "import pandas as pd\n",
    "\n",
    "# Bibliotecas de Machine Learning e Estatísticas\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#Biblioteca para salvar os resultados\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando as bibliotecas \n",
    "#%pip install pandas \n",
    "#%pip install numpy\n",
    "#%pip install imblearn\n",
    "#%pip install lazypredict\n",
    "#%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df1 = pd.read_csv('.\\Banco_de_dados\\IM_Classes_230626_semNP.csv')\n",
    "df2 = pd.read_csv('.\\Banco_de_dados\\IM_230626_semNP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando numeros nulos e duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna().drop_duplicates()\n",
    "df2 = df2.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_Documento', 'Classe_Serie', 'Numero_Cotistas', 'Quantidade_Cotas',\n",
       "       'Valor_Cota', 'Rentabilidade', 'Valor_Total_Captado',\n",
       "       'Quantidade_Cotas_Emitidas', 'Valor_Total_Resgates',\n",
       "       'Quantidade_Cotas_Resgatadas', 'Valor_A_Pagar',\n",
       "       'Quantidade_Cotas_A_Resgatar', 'Valor_Amortizado_Cota',\n",
       "       'Valor_Total_Amortizacao', 'Desempenho_Esperado',\n",
       "       'Desempenho_Realizado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colunas_1_Quero = ['SK_Documento', 'Numero_Cotistas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colunas_2_Quero = ['SK_Documento', 'CNPJ_Administrador', 'Nome_Administrador', 'Nome_Fundo',\n",
    "                   'Fundo_Exclusivo', 'Ativo', 'Ativo_Carteira', 'Ativo_Direitos_Aquisicao', \n",
    "                   'Ativo_Direitos_Aquisicao_Creditos_Vencer_Adimplentes', 'Ativo_Direitos_Aquisicao_Creditos_Inadimplentes', 'Ativo_Direitos_Sem_Aquisicao',\n",
    "                   'Ativo_Direitos_Sem_Aquisicao_Creditos_Vencer_Adimplentes', \n",
    "                   'Ativo_Direitos_Sem_Aquisicao_Creditos_Vencer_Inadimplentes', \n",
    "                   'Ativo_Valores_Mobiliarios', 'Patrimonio_Liquido', 'Liquidez_Ate_30_Dias', \n",
    "                   'Liquidez_Ate_60_Dias', 'Liquidez_Ate_90_Dias', 'Liquidez_Ate_180_Dias', 'Liquidez_Ate_360_Dias',\n",
    "                   'Liquidez_Acima_360_Dias','Carteira', 'Ativo_Direitos_Aquisicao_Parcelas_Inadimplentes', \n",
    "                   'Ativo_Direitos_Aquisicao_Creditos_Inadimplentes','Ativo_Direitos_Aquisicao_Creditos_Vencer_Inadimplentes',\"Carteira_Direitos_Aquisicao_Inadimplentes\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_colunas2 = list(df2.columns)\n",
    "for coluna in todas_colunas2:\n",
    "    if coluna not in Colunas_2_Quero:\n",
    "        df2 = df2.drop(coluna,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_colunas1 = list(df1.columns)\n",
    "for coluna in todas_colunas1:\n",
    "    if coluna not in Colunas_1_Quero:\n",
    "        df1 = df1.drop(coluna,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupando Fundos pelo SK_Documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.groupby(\"SK_Documento\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo mais um tratamento das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1,df2, on='SK_Documento', how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Nome_Administrador\",axis=1)\n",
    "df = df.drop(\"CNPJ_Administrador\",axis=1)\n",
    "df = df.drop(\"SK_Documento\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da taxa de inadimplência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Taxa_Inadimplencia\"] = df[\"Carteira_Direitos_Aquisicao_Inadimplentes\"]/df[\"Patrimonio_Liquido\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupando as features em prazos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Liquidez_curtoPrazo'] = df['Liquidez_Ate_30_Dias'] + df['Liquidez_Ate_60_Dias']\n",
    "df = df.drop(['Liquidez_Ate_30_Dias','Liquidez_Ate_60_Dias'],axis=1)\n",
    "df['Liquidez_medioPrazo'] = df['Liquidez_Ate_90_Dias'] + df['Liquidez_Ate_180_Dias']\n",
    "df = df.drop(['Liquidez_Ate_90_Dias','Liquidez_Ate_180_Dias'],axis=1)\n",
    "df['Liquidez_longoPrazo'] = df['Liquidez_Ate_360_Dias'] + df['Liquidez_Acima_360_Dias']\n",
    "df = df.drop(['Liquidez_Ate_360_Dias','Liquidez_Acima_360_Dias'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6622, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando features categóricas em numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Não', 'Sim'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fundo_Exclusivo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fundo_Exclusivo'] = df.Fundo_Exclusivo.replace({'Não':0, 'Sim':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_numericas = []\n",
    "\n",
    "for coluna in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[coluna].dtype):\n",
    "            colunas_numericas.append(coluna)\n",
    "\n",
    "df_numerico = df[colunas_numericas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as colunas numéricas \n",
    "scaler = MinMaxScaler()\n",
    "todas_colunas = list(df_numerico.columns)\n",
    "df[todas_colunas] = scaler.fit_transform(df[todas_colunas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados para clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, linha in df.iterrows():\n",
    "    if linha['Taxa_Inadimplencia'] < 0:\n",
    "        df = df.drop(index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o algorítimo para clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df['Taxa_Inadimplencia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = np.array(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6274202],\n",
       "       [0.6274202],\n",
       "       [0.6274202],\n",
       "       ...,\n",
       "       [0.6274202],\n",
       "       [0.6274202],\n",
       "       [0.6274202]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Tratar os Valores Ausentes\n",
    "data = df[['Taxa_Inadimplencia']]\n",
    "data = data.fillna(data.mean())  # Preenche os valores NaN com a média da coluna\n",
    "\n",
    "# 2. Normalizar os Dados\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# 3. Aplicar o K-means\n",
    "K = 2\n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "kmeans.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treinamento = df.drop('Nome_Fundo', axis=1)\n",
    "df_treinamento.dropna(inplace=True)\n",
    "\n",
    "X = df_treinamento.copy()\n",
    "X = X.drop(\"Cluster\", axis=1)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "Y = df_treinamento[\"Cluster\"]\n",
    "Y = Y.values.reshape(-1, 1)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X,Y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolvendo os dados desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state = 32)\n",
    "X_smote_res, Y_smote_res = smote.fit_resample(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando Lazy predict para analisar os melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:05<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30, number of negative: 4557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4845\n",
      "[LightGBM] [Info] Number of data points in the train set: 4587, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.006540 -> initscore=-5.023222\n",
      "[LightGBM] [Info] Start training from score -5.023222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LazyClassifier()\n",
    "models = clf.fit(Train_X, Test_X, Train_Y, Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descobrindo overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       " Model                                                                           \n",
       " AdaBoostClassifier                 1.00               1.00     1.00      1.00   \n",
       " BaggingClassifier                  1.00               1.00     1.00      1.00   \n",
       " XGBClassifier                      1.00               1.00     1.00      1.00   \n",
       " SVC                                1.00               1.00     1.00      1.00   \n",
       " SGDClassifier                      1.00               1.00     1.00      1.00   \n",
       " RidgeClassifierCV                  1.00               1.00     1.00      1.00   \n",
       " RidgeClassifier                    1.00               1.00     1.00      1.00   \n",
       " RandomForestClassifier             1.00               1.00     1.00      1.00   \n",
       " QuadraticDiscriminantAnalysis      1.00               1.00     1.00      1.00   \n",
       " Perceptron                         1.00               1.00     1.00      1.00   \n",
       " PassiveAggressiveClassifier        1.00               1.00     1.00      1.00   \n",
       " LogisticRegression                 1.00               1.00     1.00      1.00   \n",
       " LinearSVC                          1.00               1.00     1.00      1.00   \n",
       " LabelSpreading                     1.00               1.00     1.00      1.00   \n",
       " LabelPropagation                   1.00               1.00     1.00      1.00   \n",
       " KNeighborsClassifier               1.00               1.00     1.00      1.00   \n",
       " ExtraTreesClassifier               1.00               1.00     1.00      1.00   \n",
       " ExtraTreeClassifier                1.00               1.00     1.00      1.00   \n",
       " DecisionTreeClassifier             1.00               1.00     1.00      1.00   \n",
       " CalibratedClassifierCV             1.00               1.00     1.00      1.00   \n",
       " LGBMClassifier                     1.00               1.00     1.00      1.00   \n",
       " LinearDiscriminantAnalysis         1.00               1.00     1.00      1.00   \n",
       " NearestCentroid                    1.00               1.00     1.00      1.00   \n",
       " BernoulliNB                        0.98               0.99     0.99      0.99   \n",
       " GaussianNB                         0.97               0.98     0.98      0.98   \n",
       " DummyClassifier                    1.00               0.50     0.50      1.00   \n",
       " \n",
       "                                Time Taken  \n",
       " Model                                      \n",
       " AdaBoostClassifier                   0.07  \n",
       " BaggingClassifier                    0.23  \n",
       " XGBClassifier                        0.13  \n",
       " SVC                                  0.12  \n",
       " SGDClassifier                        0.04  \n",
       " RidgeClassifierCV                    0.04  \n",
       " RidgeClassifier                      0.04  \n",
       " RandomForestClassifier               0.68  \n",
       " QuadraticDiscriminantAnalysis        0.04  \n",
       " Perceptron                           0.03  \n",
       " PassiveAggressiveClassifier          0.03  \n",
       " LogisticRegression                   0.04  \n",
       " LinearSVC                            0.03  \n",
       " LabelSpreading                       1.80  \n",
       " LabelPropagation                     1.37  \n",
       " KNeighborsClassifier                 0.19  \n",
       " ExtraTreesClassifier                 0.24  \n",
       " ExtraTreeClassifier                  0.03  \n",
       " DecisionTreeClassifier               0.06  \n",
       " CalibratedClassifierCV               0.17  \n",
       " LGBMClassifier                       0.16  \n",
       " LinearDiscriminantAnalysis           0.04  \n",
       " NearestCentroid                      0.03  \n",
       " BernoulliNB                          0.04  \n",
       " GaussianNB                           0.04  \n",
       " DummyClassifier                      0.04  ,\n",
       "                                Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       " Model                                                                           \n",
       " AdaBoostClassifier                 1.00               1.00     1.00      1.00   \n",
       " BaggingClassifier                  1.00               1.00     1.00      1.00   \n",
       " XGBClassifier                      1.00               1.00     1.00      1.00   \n",
       " SVC                                1.00               1.00     1.00      1.00   \n",
       " SGDClassifier                      1.00               1.00     1.00      1.00   \n",
       " RidgeClassifierCV                  1.00               1.00     1.00      1.00   \n",
       " RidgeClassifier                    1.00               1.00     1.00      1.00   \n",
       " RandomForestClassifier             1.00               1.00     1.00      1.00   \n",
       " QuadraticDiscriminantAnalysis      1.00               1.00     1.00      1.00   \n",
       " Perceptron                         1.00               1.00     1.00      1.00   \n",
       " PassiveAggressiveClassifier        1.00               1.00     1.00      1.00   \n",
       " LogisticRegression                 1.00               1.00     1.00      1.00   \n",
       " LinearSVC                          1.00               1.00     1.00      1.00   \n",
       " LabelSpreading                     1.00               1.00     1.00      1.00   \n",
       " LabelPropagation                   1.00               1.00     1.00      1.00   \n",
       " KNeighborsClassifier               1.00               1.00     1.00      1.00   \n",
       " ExtraTreesClassifier               1.00               1.00     1.00      1.00   \n",
       " ExtraTreeClassifier                1.00               1.00     1.00      1.00   \n",
       " DecisionTreeClassifier             1.00               1.00     1.00      1.00   \n",
       " CalibratedClassifierCV             1.00               1.00     1.00      1.00   \n",
       " LGBMClassifier                     1.00               1.00     1.00      1.00   \n",
       " LinearDiscriminantAnalysis         1.00               1.00     1.00      1.00   \n",
       " NearestCentroid                    1.00               1.00     1.00      1.00   \n",
       " BernoulliNB                        0.98               0.99     0.99      0.99   \n",
       " GaussianNB                         0.97               0.98     0.98      0.98   \n",
       " DummyClassifier                    1.00               0.50     0.50      1.00   \n",
       " \n",
       "                                Time Taken  \n",
       " Model                                      \n",
       " AdaBoostClassifier                   0.07  \n",
       " BaggingClassifier                    0.23  \n",
       " XGBClassifier                        0.13  \n",
       " SVC                                  0.12  \n",
       " SGDClassifier                        0.04  \n",
       " RidgeClassifierCV                    0.04  \n",
       " RidgeClassifier                      0.04  \n",
       " RandomForestClassifier               0.68  \n",
       " QuadraticDiscriminantAnalysis        0.04  \n",
       " Perceptron                           0.03  \n",
       " PassiveAggressiveClassifier          0.03  \n",
       " LogisticRegression                   0.04  \n",
       " LinearSVC                            0.03  \n",
       " LabelSpreading                       1.80  \n",
       " LabelPropagation                     1.37  \n",
       " KNeighborsClassifier                 0.19  \n",
       " ExtraTreesClassifier                 0.24  \n",
       " ExtraTreeClassifier                  0.03  \n",
       " DecisionTreeClassifier               0.06  \n",
       " CalibratedClassifierCV               0.17  \n",
       " LGBMClassifier                       0.16  \n",
       " LinearDiscriminantAnalysis           0.04  \n",
       " NearestCentroid                      0.03  \n",
       " BernoulliNB                          0.04  \n",
       " GaussianNB                           0.04  \n",
       " DummyClassifier                      0.04  )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df['Taxa_Inadimplencia'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, oob_score=True, max_features=8)\n",
    "\n",
    "rf.fit(X_smote_res, Y_smote_res)\n",
    "pred_rf = rf.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = pd.Series(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.00\n",
      "f1_score 1.00\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Test_Y, pred_rf)\n",
    "print(f'Acurácia: {acc:.2f}')\n",
    "\n",
    "f1 = f1_score(Test_Y, pred_rf, average='weighted')\n",
    "print(f'f1_score {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resultado_modelo_rf.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, 'resultado_modelo_rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=49)\n",
    "\n",
    "knn.fit(X_smote_res, Y_smote_res)\n",
    "pred_knn = knn.predict(Test_X)\n",
    "\n",
    "\n",
    "mse_knn = mean_squared_error(Test_Y, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resultado_modelo_knn.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(knn, 'resultado_modelo_knn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise fundos quebrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separação dos nomes dos fundos quebrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Nome_Fundo'] = df2['Nome_Fundo']  \n",
    "fundos_quebrados = ['FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS INDIGO BARTER',\n",
    "                    'SB CRÉDITO FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS MULTISSETORIAL',\n",
    "                    'CAPTALYS FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS - MAIS LOTES',\n",
    "                    'FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS BRAVA CHALLENGE',\n",
    "                    'CREDIHOME FUNDO DE INVESTIMENTO EM DIREITOS CREDITORIOS',\n",
    "                    'SAFIRA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS',\n",
    "                    'RUBI FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS MULTISETORIAL',\n",
    "                    'FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS BULLLA',\n",
    "                    'LS INTERBANK FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS',\n",
    "                    'MANGALARGA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO-PADRONIZADOS',\n",
    "                    'TURQUESA - FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS',\n",
    "                    'ÔNIX FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADO',\n",
    "                    'RAVENNA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### criação de tabela só com esses fundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fq = df[df['Nome_Fundo'].isin(fundos_quebrados)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fq[\"Valor_em_Risco\"] = df_fq[\"Ativo_Direitos_Aquisicao_Creditos_Vencer_Inadimplentes\"]/df_fq[\"Patrimonio_Liquido\"]\n",
    "df_fq1 = df_fq.loc[(df_fq.Valor_em_Risco > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clusterização desses fundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fqt = df_fq[['Ativo', 'Valor_em_Risco']].copy()\n",
    "\n",
    "for index, linha in df_fqt.iterrows():\n",
    "    if linha['Valor_em_Risco'] == 0:\n",
    "        df_fqt = df_fqt.drop(index, axis=0)\n",
    "\n",
    "df_fqt.dropna(subset=['Ativo', 'Valor_em_Risco'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame está vazio. Verifique seus dados.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if df_fqt.empty:\n",
    "    print(\"O DataFrame está vazio. Verifique seus dados.\")\n",
    "else:\n",
    "\n",
    "    dados = df_fqt[['Ativo', 'Valor_em_Risco']].values\n",
    "\n",
    "\n",
    "    if len(dados) >= 2:  \n",
    "        K = 4\n",
    "        kmeans = KMeans(n_clusters=K, init='k-means++', random_state=42)\n",
    "        kmeans.fit(dados)\n",
    "\n",
    "        cluster_labels = kmeans.labels_\n",
    "        centroids = kmeans.cluster_centers_\n",
    "\n",
    "        print(f\"Labels dos Clusters: {cluster_labels}\")\n",
    "        print(f\"Centróides dos Clusters: {centroids}\")\n",
    "    else:\n",
    "        print(\"Não há amostras suficientes para aplicar o K-Means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by KMeans.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Inteli\\OneDrive\\Documentos\\GitHub\\grupo4_Modulo3\\notebooks\\Destiny_resume.ipynb Cell 66\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Inteli/OneDrive/Documentos/GitHub/grupo4_Modulo3/notebooks/Destiny_resume.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m K \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Inteli/OneDrive/Documentos/GitHub/grupo4_Modulo3/notebooks/Destiny_resume.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mK, init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mk-means++\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Inteli/OneDrive/Documentos/GitHub/grupo4_Modulo3/notebooks/Destiny_resume.ipynb#Y122sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m kmeans\u001b[39m.\u001b[39;49mfit(dados)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Inteli/OneDrive/Documentos/GitHub/grupo4_Modulo3/notebooks/Destiny_resume.ipynb#Y122sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cluster_labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mlabels_\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Inteli/OneDrive/Documentos/GitHub/grupo4_Modulo3/notebooks/Destiny_resume.ipynb#Y122sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m centroids \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mcluster_centers_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1471\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1443\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1445\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \n\u001b[0;32m   1447\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1472\u001b[0m         X,\n\u001b[0;32m   1473\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1474\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m   1475\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1476\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[0;32m   1477\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1478\u001b[0m     )\n\u001b[0;32m   1480\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m   1482\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    968\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 969\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    975\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    976\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by KMeans."
     ]
    }
   ],
   "source": [
    "dados = df_fqt[['Ativo', 'Valor_em_Risco']].values\n",
    "\n",
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, init='k-means++', random_state=42)\n",
    "kmeans.fit(dados)\n",
    "\n",
    "cluster_labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
