{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Destiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando pacotes e baixando banco de dados disponibilizado pela CVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalando as bibliotecas \n",
    "# %pip install pandas \n",
    "# %pip install numpy\n",
    "# %pip install imblearn\n",
    "# %pip install lazypredict\n",
    "# %pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de Manipulação de Dados e Visualização\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas de Machine Learning e Estatísticas\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo arquivo csv que será utilizado como banco de dados\n",
    "df = pd.read_csv('.\\dataset\\IM_semNP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando numeros nulos e duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando todas as linhas duplicadas e vazias \n",
    "df = df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação de uma variavel apenas com as colunas que serão utilizadas no modelo\n",
    "Colunas_Quero = [ 'Nome_Fundo',\n",
    "                   'Fundo_Exclusivo', 'Ativo', 'Ativo_Carteira', 'Ativo_Direitos_Aquisicao', \n",
    "                   'Ativo_Direitos_Aquisicao_Creditos_Vencer_Adimplentes', 'Ativo_Direitos_Aquisicao_Creditos_Inadimplentes', 'Ativo_Direitos_Sem_Aquisicao',\n",
    "                   'Ativo_Direitos_Sem_Aquisicao_Creditos_Vencer_Adimplentes', \n",
    "                   'Ativo_Direitos_Sem_Aquisicao_Creditos_Vencer_Inadimplentes', \n",
    "                   'Ativo_Valores_Mobiliarios', 'Patrimonio_Liquido', 'Liquidez_Ate_30_Dias', \n",
    "                   'Liquidez_Ate_60_Dias', 'Liquidez_Ate_90_Dias', 'Liquidez_Ate_180_Dias', 'Liquidez_Ate_360_Dias',\n",
    "                   'Liquidez_Acima_360_Dias','Carteira', 'Ativo_Direitos_Aquisicao_Parcelas_Inadimplentes', \n",
    "                   'Ativo_Direitos_Aquisicao_Creditos_Inadimplentes','Ativo_Direitos_Aquisicao_Creditos_Vencer_Inadimplentes',\"Carteira_Direitos_Aquisicao_Inadimplentes\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluindo colunas que não serão utilizadas no modelo\n",
    "todas_colunas2 = list(df.columns)\n",
    "for coluna in todas_colunas2:\n",
    "    if coluna not in Colunas_Quero:\n",
    "        df = df.drop(coluna,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da taxa de inadimplência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cálculo e criação da coluna taxa de inadimplência\n",
    "df[\"Taxa_Inadimplencia\"] = df[\"Carteira_Direitos_Aquisicao_Inadimplentes\"]/df[\"Patrimonio_Liquido\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupando as features em prazos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divisão do prazo de liquidez entre curto, médio e longo prazo\n",
    "df['Liquidez_curtoPrazo'] = df['Liquidez_Ate_30_Dias'] + df['Liquidez_Ate_60_Dias']\n",
    "df = df.drop(['Liquidez_Ate_30_Dias','Liquidez_Ate_60_Dias'],axis=1)\n",
    "df['Liquidez_medioPrazo'] = df['Liquidez_Ate_90_Dias'] + df['Liquidez_Ate_180_Dias']\n",
    "df = df.drop(['Liquidez_Ate_90_Dias','Liquidez_Ate_180_Dias'],axis=1)\n",
    "df['Liquidez_longoPrazo'] = df['Liquidez_Ate_360_Dias'] + df['Liquidez_Acima_360_Dias']\n",
    "df = df.drop(['Liquidez_Ate_360_Dias','Liquidez_Acima_360_Dias'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando features categóricas em numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando os dados da coluna fundo exclusivo em dados numericos \n",
    "df['Fundo_Exclusivo'] = df.Fundo_Exclusivo.replace({'Não':0, 'Sim':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas as colunas numericas\n",
    "colunas_numericas = []\n",
    "\n",
    "for coluna in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[coluna].dtype):\n",
    "            colunas_numericas.append(coluna)\n",
    "\n",
    "df_numerico = df[colunas_numericas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a matriz de correlação das colunas\n",
    "correlation = df_numerico.corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "plot = sns.heatmap(correlation, annot = True, fmt=\".1f\", linewidths=.1)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando gráfico da análise da taxa de inadimplência\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.title(\"Analise da taxa de inadimplência\")\n",
    "plt.xlabel(\"Index dos Fundos\")\n",
    "plt.ylabel(\"Taxa de inadimplência\")\n",
    "\n",
    "valores_y = [i * 1.5 for i in range(-50, 50)]\n",
    "plt.yticks(valores_y)\n",
    "\n",
    "plt.plot(df.index, df[\"Taxa_Inadimplencia\"], marker='o', linestyle='-', color='b', label='Dados de Exemplo')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as colunas numéricas \n",
    "scaler = MinMaxScaler()\n",
    "todas_colunas = list(df_numerico.columns)\n",
    "df[todas_colunas] = scaler.fit_transform(df[todas_colunas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados para clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas os fundos que possui taxa de inadimplência maior que 0\n",
    "for index, linha in df.iterrows():\n",
    "    if linha['Taxa_Inadimplencia'] < 0:\n",
    "        df = df.drop(index, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o algorítimo para clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tratar os Valores Ausentes\n",
    "data = df[['Taxa_Inadimplencia']]\n",
    "data = data.fillna(data.mean())  # Preenche os valores NaN com a média da coluna\n",
    "\n",
    "# 2. Aplicar o K-means\n",
    "K = 2\n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "kmeans.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "df['Cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buscando nomes de fundos saudáveis e não saudáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o desbalanceio dos dados\n",
    "df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um gráfico de dispersão dos fundos\n",
    "plt.scatter(df['Taxa_Inadimplencia'], np.zeros_like(df['Taxa_Inadimplencia']),c=df['Cluster'])\n",
    "plt.xlabel('Taxa de inadimplencia')\n",
    "plt.ylabel([])\n",
    "plt.title('Gráfico de Dispersão dos Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um novo dataframe apenas com as colunas para o terinamento\n",
    "df_treinamento = df.drop('Nome_Fundo', axis=1)\n",
    "\n",
    "# Exclui dados vazios\n",
    "df_treinamento.dropna(inplace=True)\n",
    "\n",
    "X = df_treinamento.copy()\n",
    "X = X.drop(\"Cluster\", axis=1)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "Y = df_treinamento[\"Cluster\"]\n",
    "Y = Y.values.reshape(-1, 1)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X,Y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolvendo os dados desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando um objeto\n",
    "smote = SMOTE(random_state = 32)\n",
    "\n",
    "# Balanceando os dados de treinos, para ter a mesma quantidade de fundos saudaveis e não saudaveis\n",
    "X_smote_res, Y_smote_res = smote.fit_resample(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando Lazy predict para analisar os melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analise os melhores modelos com o Lazy predict\n",
    "clf = LazyClassifier()\n",
    "models = clf.fit(Train_X, Test_X, Train_Y, Test_Y)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descobrindo overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, oob_score=True, max_features=8)\n",
    "\n",
    "rf.fit(X_smote_res, Y_smote_res)\n",
    "pred_rf = rf.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = pd.Series(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando os acertos, do modelo\n",
    "acc = accuracy_score(Test_Y, pred_rf) #Verificando a acurácia do modelo\n",
    "print(f'Acurácia: {acc:.2f}')\n",
    "\n",
    "f1 = f1_score(Test_Y, pred_rf, average='weighted') #Verificando o F1 score do modelo\n",
    "print(f'f1_score {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise fundos quebrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separação dos nomes dos fundos quebrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista com nomes de fundos que sabemos que quebraram\n",
    "fundos_quebrados = ['FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS INDIGO BARTER',\n",
    "                    'SB CRÉDITO FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS MULTISSETORIAL',\n",
    "                    'CAPTALYS FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS - MAIS LOTES',\n",
    "                    'FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS BRAVA CHALLENGE',\n",
    "                    'CREDIHOME FUNDO DE INVESTIMENTO EM DIREITOS CREDITORIOS',\n",
    "                    'SAFIRA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS',\n",
    "                    'RUBI FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS MULTISETORIAL',\n",
    "                    'FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS BULLLA',\n",
    "                    'LS INTERBANK FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS',\n",
    "                    'MANGALARGA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO-PADRONIZADOS',\n",
    "                    'TURQUESA - FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS',\n",
    "                    'ÔNIX FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADO',\n",
    "                    'RAVENNA FUNDO DE INVESTIMENTO EM DIREITOS CREDITÓRIOS NÃO PADRONIZADOS',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### criação de tabela com os fundos quebrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de tabela apenas com os fundos quebrados\n",
    "df_fq = df[df['Nome_Fundo'].isin(fundos_quebrados)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do valor em risco \n",
    "df_fq[\"Valor_em_Risco\"] = df_fq[\"Ativo_Direitos_Aquisicao_Creditos_Vencer_Inadimplentes\"]/df_fq[\"Patrimonio_Liquido\"]\n",
    "df_fq1 = df_fq.loc[(df_fq.Valor_em_Risco > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analise do valor de risco dos fundos quebrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de grafico com análise do valor em risco dos fundos quebrados\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.title(\"Analise do valor em risco do fundos\")\n",
    "plt.xlabel(\"Index dos Fundos\")\n",
    "plt.ylabel(\"Valor em risco\")\n",
    "\n",
    "valores_y = [i * 0.50 for i in range(0, 50)]\n",
    "plt.yticks(valores_y)\n",
    "\n",
    "plt.plot(df_fq1.index, df_fq1[\"Valor_em_Risco\"], marker='o', linestyle='-', color='b', label='Dados de Exemplo')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clusterização dos fundos quebrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusterizando fundos quebrados\n",
    "df_fqt = df_fq[['Ativo', 'Valor_em_Risco']].copy()\n",
    "\n",
    "for index, linha in df_fqt.iterrows():\n",
    "    if linha['Valor_em_Risco'] == 0:\n",
    "        df_fqt = df_fqt.drop(index, axis=0)\n",
    "\n",
    "df_fqt.dropna(subset=['Ativo', 'Valor_em_Risco'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dados para clusterização dos fundos quebrados\n",
    "if df_fqt.empty:\n",
    "    print(\"O DataFrame está vazio. Verifique seus dados.\")\n",
    "else:\n",
    "\n",
    "    dados = df_fqt[['Ativo', 'Valor_em_Risco']].values\n",
    "\n",
    "\n",
    "    if len(dados) >= 2:  \n",
    "        K = 4\n",
    "        kmeans = KMeans(n_clusters=K, init='k-means++', random_state=42)\n",
    "        kmeans.fit(dados)\n",
    "\n",
    "        cluster_labels = kmeans.labels_\n",
    "        centroids = kmeans.cluster_centers_\n",
    "\n",
    "        print(f\"Labels dos Clusters: {cluster_labels}\")\n",
    "        print(f\"Centróides dos Clusters: {centroids}\")\n",
    "    else:\n",
    "        print(\"Não há amostras suficientes para aplicar o K-Means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df_fqt[['Ativo', 'Valor_em_Risco']].values\n",
    "\n",
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, init='k-means++', random_state=42)\n",
    "kmeans.fit(dados)\n",
    "\n",
    "cluster_labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de gráfico com a disperção dos clusters dos fundos quebrados\n",
    "plt.scatter(df_fqt['Ativo'], df_fqt['Valor_em_Risco'], c=cluster_labels)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', c='red', s=100)\n",
    "plt.xlabel('Ativo')\n",
    "plt.ylabel('Valor em Risco')\n",
    "plt.title('Gráfico de Dispersão dos Clusters')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
